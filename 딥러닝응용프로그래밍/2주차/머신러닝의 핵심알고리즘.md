<div align="center">
  <h2>인공지능개론 복습</h2>
</div align="center"> 

### 💙 01 머신러닝의 엄밀한 정의

#### 🟦 머신러닝의 정의
```
🟦 인공지능: 컴퓨터를 사용하여 인간의 지능을 구현하려는 기술
🟦 머신러닝: 명시적 프로그래밍없이 컴퓨터가 학습을 통해 작업 성능을 높여나가는 기술
```
#### 🟦 톰미첼의 정의
```
'어떤 작업 T에 속한 작업을 수행하며 경험 E에 따라서 P로 측정하는 성능이 개선된다면,
이 프로그램은 작업 T와 성능 척도 P에 대해 경험 E로부터 학습한다고 말할 수 있다'
```
```
ex) 0~9까지 숫자에 대한 손글씨 이미지를 숫자로 인식시키는 과정에서 머신러닝을 사용했다고 가정
- 작업 T: 손글씨 이미지를 숫자로 인식하여 분류
- 성능 척도 P: 전체 손글씨에 대해 정확하게 분류한 손글씨의 비율
- 경험 E: 손글씨 숫자 데이터들과 정확한 글자를 표현한 데이터 집합 
```
#### 🟦 명시적 프로그래밍과 머신러닝
```
명시적 프로그래밍은, 데이터를 입력으로 받아 명시적인 규칙을 통해 출력을 내보내느 절차
-> 머신러닝 알고리즘이 아니므로 성능 척도 평가 X, 제한적인 일만 가능
머신러닝은, 데이터와 출력 결과를 보고 이를 바탕으로 규칙을 학습한 다음 규칙을 생성하는 방식
-> 데이터에 대해 규칙을 적용하고, 잘 동작하지 않으면 규칙을 갱신하는 방법 채택
```
```
ex) 고객의 키에 따른 분류 기준 값을 찾는다면,
- 작업 T: 키 데이터 사용하여 이용 가능, 불가능 고객의 분류 기준값을 찾음
- 성능 척도 P: 기준값을 적용하여 발생한 오류의 개수
- 경험 E: 오류의 개수가 적게 나오도록 분류를 위한 기준값 변경 
```
#### 🟦 머신러닝은 데이터를 기반으로 학습하여 작업 성능을 개선하는 알고리즘 
```
머신러닝 알고리즘은 흔히 모델, model 이라고도 부름
1. 명시적 프로그램에 비해 코드를 유지보수하기 쉬움 -> 항상 최상의 상태로 유지하기 위한
2. 명시적 프로그램으로 해결 방법이 없는 복잡한 문제도 해결 가능
3. 새로운 데이터에 대해서도 규칙을 생성하여 문제를 풀 수 있음
4. 복잡한 문제나 대량의 데이터에 대해서 미처 알지 못했던 통찰 얻음 
```
||명시적 프로그래밍|머신러닝|
|---------------------|-------|---------|
|설명|특정한 작업을 수행하는 방법을 일일이 지시하는 문장으로 이루어진다|데이터를 이용하여 학습을 수행한 다음 규칙을 생성하는 방식으로 동작|
|예시 <br>(손글씨 숫자 인식)|개별적인 손글씨를 인식하기 위하여 각각의 규칙을 만든다<br> ex) 숫자 0은 하나의 닫힌 원으로 정의|많은 숫자 예제 데이터를 이용해 각각의 특징을 프로그램이 학습하여 규칙을 얻음|
|단점|정의한 규칙을 벗어나는 예외적인 경우에 대해 적절한 해를 내보내지 못함 <br> ex) 0의 위쪽에 약간의 틈이 있으면 0이라고 인식 X|학습을 위한 많은 데이터 필요, 학습에 소요되는 시간 증가|

### 💙 02 선형 회귀를 통해 살펴보는 머신러닝
#### 🟦 선형 회귀란?
```
🟦 회귀: 어딘가로 돌아간다 by 프랜시스 골턴
```

```
존재하는 데이터를 바탕으로 y=2x와 같은 직선의 방정식을 얻기 위해 머신러닝은 어떤 방법을 사용할까.
선형 회귀 직선의 기울기를 m으로 표기하고, 이 값을 구하는 문제로 바꾸어 생각
모델은 선형 회귀 알고리즘이 되며, 모델의 기울기에 해당하는 m은 조절 가능한 변수로 '파라미터'
```
```
🟦 변하는 양 -> 변수
🟦 두 개의 변수들이 함께 변화하는 관계 -> 상관관계
🟦 변수들 사이의 상관관계 정도를 나타내는 수치 -> 상관계수
```
```
한쪽의 값이 커질 때 다른 쪽의 값도 커지는 경우를 양의 상관관계라고 정의하며 데이터의 분포를 설명하는 직선을 '선형회귀 직선'
이 직선의 함수를 선형 회귀 함수라고 하며, 선형 회귀는 실제 데이터를 바탕으로 새로운 데이터가 입력되었을 경우 출력 결과를 예측
```

```
1️⃣ 직선이 실제 데이터의 분포와 차이가 크다 = 오차가 크다
2️⃣ 직선이 실제 데이터의 분포와 차이가 작다 = 오차가 작다
3️⃣ 직선이 실제 데이터의 분포와 차이가 매우 적다 = 오차가 매우 작다
==> 오차의 합(성능 P)이 점점 작아진다 = 좋은 모델(경험 E)
```
```
1️⃣ 오차값의 평균: MAE (e1 + e2 + e3) / 데이터의 개수
2️⃣ 오차 제곱값의 평균(음영 상자 면적의 평균): MSE (e1*e1 + e2*e2 + e3*e3) / 데이터의 개수
```
```
오차의 합을 구하고 그것을 데이터의 개수으로 나누어 평균을 구하여 얻은 오차값 -> 평균 절대값 오차
오차 제곱값의 평균으로 오차를 측정 -> 평균 제곱 오차
but 오차가 매우 클 경우 성능 측정 함수 P의 값이 급격하게 커짐
선형 회귀 모델이 예측한 직선이 실제 데이터와 차이가 많이 나면, 이 모델의 성능이 나쁘도록 알림
성능이 나쁜 모델 -> 좋은 모델이 된다면 '머신러닝 알고리즘'
회귀 모델의 오차는 일반적으로 평균 제곱 오차를 사용,
오차의 제곱은 오차 직선을 한 변으로 하는 정사각형의 면적과 같고 항상 양수가 됨
선형 회귀 직선이 데이터의 분포를 가장 잘 설명하는 경우 MSE 값은 최소값
==> 데이터의 분포를 가장 잘 설명하는 선형 회귀 직선을 구하는 과정을 '최적화' = 머신러닝의 학습과정 
```
#### 🟦 MSE 곡선의 최적값을 구하는 기울기와 미분
```
ex) MSE 곡선의 가장 낮은 부분이 최적값일 때
작업 T는 곡선 MSE의 최적값 구하기 -> 성능 척도 P로 측정
곡선에서 임의의 한 점 기울기를 구하고 양의 기울기인지 음의 기울기인지 판단
==> 기울기와 부호를 구한 후 곡선의 아래쪽으로 향하도록 다음 값을 조정, 다시 오차를 구하고, 곡면 기울기를 구하는 작업 반복 수행: 경험 E
==> 반복적인 동작(학습)을 통해 곡선의 값이 더 작아지는 방향으로 이동시켜 최적값에 도달시킴 
```
##### 🔴 **경사하강법** : MSE 곡선과 같은 오차 곡선의 극소값을 향하도록 반복적으로 파라미터를 조절하는 최적화 기법

### 💙 다양한 머신러닝 학습 방법

#### 🟦 지도학습, 비지도학습, 강화학습

##### 🔴 지도학습
```
지도학습에서 컴퓨터는 '교사'에 의해 데이터와 레이블(정답)을 제공받음
지도학습의 목표는 입력을 출력에 매핑하는 일반적인 규칙을 학습하는 것
ex) 고양이와 개를 구분할 때 교사가 고양이와 개로 레이블링된 데이터를 충분히 제공한 뒤에 학습하는 과정 필요
학습 단계에서 만들어진 예측 모델은 테스트 단계에서 새로운 데이터를 만나며, 이전의 학습을 바탕으로 맞힘
```
##### 🔴 비지도학습
```
비지도학습은 외부에서 레이블을 주지 않고 학습 알고리즘이 스스로 입력으로부터 특정한 구조나 숨겨진 패턴을 발견함
ex) 군집화: 주어진 데이터를 특성에 따라 둘 이상의 그룹으로 나눔 -> 특성을 구분하는 방법을 컴퓨터가 학습
```
##### 🔴 강화학습
```
강화학습은 실수로부터 학습하는 방법
데이터에서 레이블을 구하거나 패턴을 찾는 방식이 아니며 학습할 데이터를 사전에 주지 않아도 됨
강화학습에서는 에이전트, 환경, 행동, 보상, 상태라는 학습 데이터가 주어짐
ex) 게임 캐릭터(에이전트)가 주어진 '환경'에서 특정한 '행동'을 수행하고, 이에 대한 '보상'이 주어질 경우
이 보상을 '최대화'하는 행동을 결정하는 '정책'을 바꾸어 나가는 방식 
```
#### 🟦 강화학습에서 사용되는 주요 용어
|용어|설명|
|---|---|
|에이전트|행위자, 주어진 문제 상황에서 행동하는 주체|
|환경|에이전트가 상호작용해야할 문제, 물리적 세계|
|행동|에이전트가 선택할 수 있는 선택지|
|상태|환경의 모든 정보, 현재 시점의 상황|
|보상|행동을 취했을 때 따라오는 이득 or 벌칙|
|정책|행동을 선택할 때 사용하는 규칙|
##### 🔴 강화학습에서 사용되는 보상의 의미: 알고리즘의 학습에 쓰이는 수치값, 음수일 경우 벌칙 
#### 🟦 회귀와 분류
```
지도학습에서 주어진 데이터를 바탕으로 예측하고자 하는 것이 무엇인지에 따라 회귀와 분류로 나뉨
예측하고 싶은 종속 변수가 숫자일 때는 회귀, 예측하고자 하는 목표값이 범주형일 경우 분류 기법 사용
범주형 변수란? 연속적이지않은 이산적인 값을 가지는 변수
분류 문제에서 나누어야 할 목표값을 '클래스', 클래스가 두 가지인 경우 이진 분류, 둘 이상이면 다중 분류
```
|이진분류|다중분류|
|--|--|
|스팸메일 판별: 이다 or 아니다 <br> 신용카드 사기거래 탐지: 사기 or 정당한 거래 <br> x선 종양 탐지: 악성 or 양성|그림 이미지 분류: 삼각, 사각, 오각형 나누기 <br> 숫자 이미지 데이터 분류: 0~9까지의 숫자 중 <br> 동물 이미지 데이터 분류 <br> 뉴스 기사 분류|

### 💙 04 다양한 지도학습 방법
#### 🟦 K-최근접 이웃 알고리즘
##### 🔴 k-Nearest Neighbor의 약자를 따서 K-NN 알고리즘 
##### => k개의 가장 가까운 이웃을 살펴보고 다수결 방식으로 데이터의 레이블을 할당하는 분류 방식 
```
ex) 남극의 펭귄 중 중형 펭귄인 아델리 펭귄과 대형 펭귄인 황제 펭귄에 대해 분류한다면,
표본 공간에서 키와 몸무게는 속성 feature이 되며, 펭귄 두 종류는 레이블 label이 됨
키와 몸무게라는 속성을 가지고 있고 레이블이 없는 펭귄이 있다고 가정하고, knn 알고리즘의 k값을 5라 한다면
가장 가까운 이웃을 비교했을 때 다수결에 의해 새로운 데이터의 레이블을 표시하면 됨
==> K-NN 알고리즘은 학습 데이터 안에 존재하는 노이즈의 영향을 크게 받지 않으며,
학습 데이터의 수가 많을 때는 꽤 효과적인 분류 성능을 보여주게 된다
```
#### 🟦 서포트 벡터 머신
##### 🔴 서포트 벡터 머신 support vector machine = SVM 
##### => 머신러닝 분야에서의 데이터 분류 방법으로 '경계를 만들어 데이터를 분리하는 분류 방법'
##### => 두 데이터 그룹을 나누는 평면 중에서 가장 폭이 넓은 것을 찾는 방법, 가장 넓은 틈을 가로지르는 선
```
🟦 결정 경계: 분리 평면
🟦 초평면: 결정 경계면은 2차원에서는 직선이지만 그 이상의 새로운 차원에서는 가시화할 수 없는 평면
🟦 마진: 결정 경계와 서포트 벡터머신 사이(결정 경계에 가장 가까운 데이터)의 거리
```
```
학습 알고리즘은 각 그룹의 중심점을 구한 후, 중심점 두 개를 잇고 그 가운데를 지나는 최적의 결정 경계면을 구해 두 데이터 그룹을 나누는 방법을 학습
==> 직선으로 나눌 수 있다면 선형 분류 모델, 직선으로 나눌 수 없다면 비선형 분류 모델 적용
```
#### 🟦 결정트리 
